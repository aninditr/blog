<!DOCTYPE html>
<html lang="en-US" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-beta.51" />
    <meta name="theme" content="VuePress Theme Hope" />
    <meta property="og:url" content="https://aninditr.github.io/blog/BERTScore/"><meta property="og:site_name" content="MLNLP Blog"><meta property="og:title" content="BERTScore - Evaluating Text Generation with BERT"><meta property="og:type" content="article"><meta property="og:updated_time" content="2023-11-19T23:23:02.000Z"><meta property="og:locale" content="en-US"><meta property="article:author" content="Aninditha Ramesh, Srikumar Subramanian"><meta property="article:tag" content="BERTScore"><meta property="article:tag" content="Multilingual MT"><meta property="article:tag" content="Evaluation"><meta property="article:published_time" content="2023-11-16T00:00:00.000Z"><meta property="article:modified_time" content="2023-11-19T23:23:02.000Z"><title>BERTScore - Evaluating Text Generation with BERT | MLNLP Blog</title><meta name="description" content="A Blog for Machine Learning, Natural Language Processing, and Data Mining">
    <style>
      :root {
        --bg-color: #fff;
      }

      html[data-theme="dark"] {
        --bg-color: #1d2025;
      }

      html,
      body {
        background-color: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.querySelector("html").setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="stylesheet" href="/blog/assets/style.758fbe27.css">
    <link rel="modulepreload" href="/blog/assets/app.a2f2e5e3.js"><link rel="modulepreload" href="/blog/assets/index.html.29bfbf7f.js"><link rel="modulepreload" href="/blog/assets/_plugin-vue_export-helper.cdc0426e.js"><link rel="modulepreload" href="/blog/assets/index.html.48a6c22d.js"><link rel="prefetch" href="/blog/assets/index.html.0a2dc172.js"><link rel="prefetch" href="/blog/assets/index.html.b61f3936.js"><link rel="prefetch" href="/blog/assets/index.html.a04f8d03.js"><link rel="prefetch" href="/blog/assets/index.html.95d6e27c.js"><link rel="prefetch" href="/blog/assets/index.html.68f163fb.js"><link rel="prefetch" href="/blog/assets/index.html.dcc4e033.js"><link rel="prefetch" href="/blog/assets/index.html.0fe7b4d2.js"><link rel="prefetch" href="/blog/assets/index.html.545afc23.js"><link rel="prefetch" href="/blog/assets/index.html.50a208c9.js"><link rel="prefetch" href="/blog/assets/index.html.ca3eb513.js"><link rel="prefetch" href="/blog/assets/index.html.1683180a.js"><link rel="prefetch" href="/blog/assets/index.html.67f9d527.js"><link rel="prefetch" href="/blog/assets/index.html.5cbbd239.js"><link rel="prefetch" href="/blog/assets/index.html.3daa1d0a.js"><link rel="prefetch" href="/blog/assets/index.html.e621fb04.js"><link rel="prefetch" href="/blog/assets/index.html.e7128c12.js"><link rel="prefetch" href="/blog/assets/index.html.441d3292.js"><link rel="prefetch" href="/blog/assets/index.html.1ddfcd16.js"><link rel="prefetch" href="/blog/assets/index.html.8fa42235.js"><link rel="prefetch" href="/blog/assets/index.html.0121e0e4.js"><link rel="prefetch" href="/blog/assets/index.html.8116b712.js"><link rel="prefetch" href="/blog/assets/index.html.70e56272.js"><link rel="prefetch" href="/blog/assets/index.html.7e11e5e3.js"><link rel="prefetch" href="/blog/assets/404.html.7774e075.js"><link rel="prefetch" href="/blog/assets/index.html.e6984e6d.js"><link rel="prefetch" href="/blog/assets/index.html.e244bd28.js"><link rel="prefetch" href="/blog/assets/index.html.51423517.js"><link rel="prefetch" href="/blog/assets/index.html.20c404ea.js"><link rel="prefetch" href="/blog/assets/index.html.03d06508.js"><link rel="prefetch" href="/blog/assets/index.html.5512c497.js"><link rel="prefetch" href="/blog/assets/index.html.173e9ede.js"><link rel="prefetch" href="/blog/assets/index.html.afad03ac.js"><link rel="prefetch" href="/blog/assets/index.html.5eb70ef0.js"><link rel="prefetch" href="/blog/assets/index.html.725854e4.js"><link rel="prefetch" href="/blog/assets/index.html.8d6add0f.js"><link rel="prefetch" href="/blog/assets/index.html.c6992606.js"><link rel="prefetch" href="/blog/assets/index.html.f2ba2527.js"><link rel="prefetch" href="/blog/assets/index.html.84859280.js"><link rel="prefetch" href="/blog/assets/index.html.d9448a51.js"><link rel="prefetch" href="/blog/assets/index.html.04e85a8c.js"><link rel="prefetch" href="/blog/assets/index.html.37e50a22.js"><link rel="prefetch" href="/blog/assets/index.html.50b36fc5.js"><link rel="prefetch" href="/blog/assets/index.html.45d14c94.js"><link rel="prefetch" href="/blog/assets/index.html.2a4773e0.js"><link rel="prefetch" href="/blog/assets/index.html.ab91f42d.js"><link rel="prefetch" href="/blog/assets/index.html.2bcffee1.js"><link rel="prefetch" href="/blog/assets/index.html.dd1e0de1.js"><link rel="prefetch" href="/blog/assets/index.html.99eb93c5.js"><link rel="prefetch" href="/blog/assets/index.html.fa64b8d6.js"><link rel="prefetch" href="/blog/assets/index.html.16e04112.js"><link rel="prefetch" href="/blog/assets/index.html.55e73b8f.js"><link rel="prefetch" href="/blog/assets/index.html.5a6a0eb3.js"><link rel="prefetch" href="/blog/assets/index.html.a0ad8a19.js"><link rel="prefetch" href="/blog/assets/index.html.b15a8f64.js"><link rel="prefetch" href="/blog/assets/index.html.00a9cc03.js"><link rel="prefetch" href="/blog/assets/index.html.666a9d20.js"><link rel="prefetch" href="/blog/assets/index.html.7d5b7751.js"><link rel="prefetch" href="/blog/assets/index.html.cf624902.js"><link rel="prefetch" href="/blog/assets/index.html.197c772d.js"><link rel="prefetch" href="/blog/assets/index.html.c27c37cb.js"><link rel="prefetch" href="/blog/assets/index.html.976495a8.js"><link rel="prefetch" href="/blog/assets/index.html.dac5c754.js"><link rel="prefetch" href="/blog/assets/index.html.413a795e.js"><link rel="prefetch" href="/blog/assets/index.html.9f3cea39.js"><link rel="prefetch" href="/blog/assets/index.html.3d095a87.js"><link rel="prefetch" href="/blog/assets/index.html.07ad5d0d.js"><link rel="prefetch" href="/blog/assets/index.html.bed79ab3.js"><link rel="prefetch" href="/blog/assets/index.html.cdbae4a6.js"><link rel="prefetch" href="/blog/assets/index.html.cd39c4bc.js"><link rel="prefetch" href="/blog/assets/index.html.2b1ad648.js"><link rel="prefetch" href="/blog/assets/index.html.4807ccce.js"><link rel="prefetch" href="/blog/assets/index.html.df380c03.js"><link rel="prefetch" href="/blog/assets/index.html.bb93052a.js"><link rel="prefetch" href="/blog/assets/index.html.0b2b7f2b.js"><link rel="prefetch" href="/blog/assets/index.html.b703fa27.js"><link rel="prefetch" href="/blog/assets/index.html.c63b759e.js"><link rel="prefetch" href="/blog/assets/index.html.4e14b91e.js"><link rel="prefetch" href="/blog/assets/index.html.61d59017.js"><link rel="prefetch" href="/blog/assets/index.html.b3567cfa.js"><link rel="prefetch" href="/blog/assets/index.html.73a7058b.js"><link rel="prefetch" href="/blog/assets/index.html.b36d2799.js"><link rel="prefetch" href="/blog/assets/index.html.dbf3f3d8.js"><link rel="prefetch" href="/blog/assets/index.html.d058567c.js"><link rel="prefetch" href="/blog/assets/index.html.d88b79c1.js"><link rel="prefetch" href="/blog/assets/index.html.b7a52240.js"><link rel="prefetch" href="/blog/assets/index.html.29f345ed.js"><link rel="prefetch" href="/blog/assets/index.html.7407918c.js"><link rel="prefetch" href="/blog/assets/index.html.63af168d.js"><link rel="prefetch" href="/blog/assets/index.html.73aa1c8b.js"><link rel="prefetch" href="/blog/assets/index.html.47c9e20d.js"><link rel="prefetch" href="/blog/assets/index.html.42231314.js"><link rel="prefetch" href="/blog/assets/index.html.e7ab628f.js"><link rel="prefetch" href="/blog/assets/index.html.f45434b1.js"><link rel="prefetch" href="/blog/assets/index.html.44b8cf99.js"><link rel="prefetch" href="/blog/assets/index.html.aacf5ef7.js"><link rel="prefetch" href="/blog/assets/index.html.c8684006.js"><link rel="prefetch" href="/blog/assets/index.html.a338fcbb.js"><link rel="prefetch" href="/blog/assets/index.html.99e1e528.js"><link rel="prefetch" href="/blog/assets/index.html.804c9893.js"><link rel="prefetch" href="/blog/assets/404.html.ef5a2683.js"><link rel="prefetch" href="/blog/assets/index.html.a6cc6b38.js"><link rel="prefetch" href="/blog/assets/index.html.8a36780a.js"><link rel="prefetch" href="/blog/assets/index.html.2099962d.js"><link rel="prefetch" href="/blog/assets/index.html.de969661.js"><link rel="prefetch" href="/blog/assets/index.html.2600f134.js"><link rel="prefetch" href="/blog/assets/index.html.c4fa2d31.js"><link rel="prefetch" href="/blog/assets/index.html.557432b1.js"><link rel="prefetch" href="/blog/assets/index.html.3d05c709.js"><link rel="prefetch" href="/blog/assets/index.html.3ea50958.js"><link rel="prefetch" href="/blog/assets/index.html.158db12c.js"><link rel="prefetch" href="/blog/assets/index.html.66c09150.js"><link rel="prefetch" href="/blog/assets/index.html.8846c5c5.js"><link rel="prefetch" href="/blog/assets/index.html.f49f6516.js"><link rel="prefetch" href="/blog/assets/index.html.dabb585f.js"><link rel="prefetch" href="/blog/assets/index.html.6b95ba44.js"><link rel="prefetch" href="/blog/assets/index.html.2caa13ba.js"><link rel="prefetch" href="/blog/assets/index.html.26a6921f.js"><link rel="prefetch" href="/blog/assets/index.html.c46be577.js"><link rel="prefetch" href="/blog/assets/index.html.e70d2799.js"><link rel="prefetch" href="/blog/assets/index.html.e2996c93.js"><link rel="prefetch" href="/blog/assets/index.html.a307a7b2.js"><link rel="prefetch" href="/blog/assets/index.html.ef5691b2.js"><link rel="prefetch" href="/blog/assets/index.html.af492a83.js"><link rel="prefetch" href="/blog/assets/index.html.15734044.js"><link rel="prefetch" href="/blog/assets/index.html.eff00532.js"><link rel="prefetch" href="/blog/assets/index.html.1c6f4b33.js"><link rel="prefetch" href="/blog/assets/index.html.44811afd.js"><link rel="prefetch" href="/blog/assets/index.html.feb89e27.js"><link rel="prefetch" href="/blog/assets/index.html.4bba06b8.js"><link rel="prefetch" href="/blog/assets/index.html.6be996d0.js"><link rel="prefetch" href="/blog/assets/index.html.ea335785.js"><link rel="prefetch" href="/blog/assets/index.html.80e87726.js"><link rel="prefetch" href="/blog/assets/index.html.f51c99b4.js"><link rel="prefetch" href="/blog/assets/index.html.c726fd1c.js"><link rel="prefetch" href="/blog/assets/index.html.208ea47c.js"><link rel="prefetch" href="/blog/assets/index.html.793e3d1c.js"><link rel="prefetch" href="/blog/assets/index.html.5298f92d.js"><link rel="prefetch" href="/blog/assets/index.html.eddd1cd6.js"><link rel="prefetch" href="/blog/assets/index.html.6506c13a.js"><link rel="prefetch" href="/blog/assets/index.html.f9444a0a.js"><link rel="prefetch" href="/blog/assets/index.html.4bf7497b.js"><link rel="prefetch" href="/blog/assets/index.html.f9775e0e.js"><link rel="prefetch" href="/blog/assets/index.html.2f392172.js"><link rel="prefetch" href="/blog/assets/index.html.6a8b8dc8.js"><link rel="prefetch" href="/blog/assets/index.html.afa7a805.js"><link rel="prefetch" href="/blog/assets/index.html.df2e81f0.js"><link rel="prefetch" href="/blog/assets/index.html.8725dc63.js"><link rel="prefetch" href="/blog/assets/index.html.c4a85814.js"><link rel="prefetch" href="/blog/assets/index.html.07fb6ff2.js"><link rel="prefetch" href="/blog/assets/index.html.87a38cc7.js"><link rel="prefetch" href="/blog/assets/index.html.d124035c.js"><link rel="prefetch" href="/blog/assets/index.html.f7cbff7d.js"><link rel="prefetch" href="/blog/assets/giscus.15440425.js"><link rel="prefetch" href="/blog/assets/highlight.esm.d982e650.js"><link rel="prefetch" href="/blog/assets/markdown.esm.832a189d.js"><link rel="prefetch" href="/blog/assets/math.esm.a3f84b6f.js"><link rel="prefetch" href="/blog/assets/notes.esm.3c361cb7.js"><link rel="prefetch" href="/blog/assets/reveal.esm.b96f05d8.js"><link rel="prefetch" href="/blog/assets/search.esm.80da4a02.js"><link rel="prefetch" href="/blog/assets/zoom.esm.8514a202.js"><link rel="prefetch" href="/blog/assets/photoswipe.esm.382b1873.js">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="skip-link sr-only">Skip to content</a><!--]--><div class="theme-container no-sidebar has-toc"><!--[--><!--[--><header class="navbar"><div class="navbar-left"><button class="toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!----><a href="/blog/" class="brand"><img class="logo" src="/blog/logo.svg" alt="MLNLP Blog"><!----><span class="site-name hide-in-pad">MLNLP Blog</span></a><!----></div><div class="navbar-center"><!----><nav class="nav-links"><div class="nav-item hide-in-mobile"><a href="/blog/" class="nav-link" aria-label="Blog Home"><span class="icon iconfont icon-home"></span>Blog Home<!----></a></div><div class="nav-item hide-in-mobile"><a href="/blog/category/" class="nav-link" aria-label="Category"><span class="icon iconfont icon-categoryselected"></span>Category<!----></a></div><div class="nav-item hide-in-mobile"><a href="/blog/tag/" class="nav-link" aria-label="Tags"><span class="icon iconfont icon-tag"></span>Tags<!----></a></div><div class="nav-item hide-in-mobile"><a href="/blog/timeline/" class="nav-link" aria-label="Timeline"><span class="icon iconfont icon-time"></span>Timeline<!----></a></div></nav><!----></div><div class="navbar-right"><!----><!----><div class="nav-item"><a class="repo-link" href="https://github.com/aninditr/blog" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewbox="0 0 1024 1024" fill="currentColor" aria-label="github icon" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="nav-item hide-in-mobile"><button id="appearance-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewbox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewbox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewbox="0 0 1024 1024" fill="currentColor" aria-label="light icon" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><form class="search-box" role="search"><input type="search" autocomplete="off" spellcheck="false" value><!----></form><!----><button class="toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span class="button-container"><span class="button-top"></span><span class="button-middle"></span><span class="button-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow left"></span></div><aside class="sidebar"><!--[--><!----><!--]--><ul class="sidebar-links"></ul><!--[--><!----><!--]--></aside><!--[--><main class="page" id="main-content"><!--[--><!----><nav class="breadcrumb disable"></nav><div class="page-title"><h1><!---->BERTScore - Evaluating Text Generation with BERT</h1><div class="page-info"><span class="author-info" aria-label="Author🖊" data-balloon-pos="down" localizeddate="November 16, 2023" isoriginal="false" pageview="false"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewbox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><span class="author-item">Aninditha Ramesh, Srikumar Subramanian</span></span><span property="author" content="Aninditha Ramesh, Srikumar Subramanian"></span></span><!----><span class="date-info" aria-label="Writing Date📅" data-balloon-pos="down" isoriginal="false" pageview="false"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewbox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span>November 16, 2023</span><meta property="datePublished" content="2023-11-16T00:00:00.000Z"></span><span class="category-info" aria-label="Category🌈" data-balloon-pos="down" localizeddate="November 16, 2023" isoriginal="false" pageview="false"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewbox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><ul class="categories-wrapper"><li class="category category4 clickable" role="navigation">MT</li><meta property="articleSection" content="MT"></ul></span><span aria-label="Tag🏷" data-balloon-pos="down" localizeddate="November 16, 2023" isoriginal="false" pageview="false"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewbox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><ul class="tags-wrapper"><li class="tag tag7 clickable" role="navigation">BERTScore</li><li class="tag tag7 clickable" role="navigation">Multilingual MT</li><li class="tag tag3 clickable" role="navigation">Evaluation</li></ul><meta property="keywords" content="BERTScore,Multilingual MT,Evaluation"></span><span class="reading-time-info" aria-label="Reading Time⌛" data-balloon-pos="down" localizeddate="November 16, 2023" isoriginal="false" pageview="false"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewbox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>About 6 min</span><meta property="timeRequired" content="PT6M"></span></div><hr></div><div class="toc-place-holder"><aside id="toc"><div class="toc-header">On This Page</div><div class="toc-wrapper"><ul class="toc-list"><!--[--><li class="toc-item"><a aria-current="page" href="/blog/BERTScore/#introduction" class="router-link-active router-link-exact-active toc-link level2">Introduction</a></li><!----><!--]--><!--[--><li class="toc-item"><a aria-current="page" href="/blog/BERTScore/#issues-with-current-metrics" class="router-link-active router-link-exact-active toc-link level2">Issues with current metrics</a></li><!----><!--]--><!--[--><li class="toc-item"><a aria-current="page" href="/blog/BERTScore/#how-bertscore-works" class="router-link-active router-link-exact-active toc-link level2">How BERTScore works</a></li><!----><!--]--><!--[--><li class="toc-item"><a aria-current="page" href="/blog/BERTScore/#experiments" class="router-link-active router-link-exact-active toc-link level2">Experiments</a></li><!----><!--]--><!--[--><li class="toc-item"><a aria-current="page" href="/blog/BERTScore/#results" class="router-link-active router-link-exact-active toc-link level2">Results</a></li><!----><!--]--><!--[--><li class="toc-item"><a aria-current="page" href="/blog/BERTScore/#references" class="router-link-active router-link-exact-active toc-link level2">References</a></li><!----><!--]--></ul></div></aside></div><!----><div class="theme-hope-content"><p>In this paper, we will explore the BERTScore text evaluation metric from the paper <em>BERTScore - Evaluating Text Generation with BERT</em></p><p>Paper：<a href="https://arxiv.org/pdf/1904.09675.pdf" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/1904.09675.pdf<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p>Github: <a href="https://github.com/Tiiiger/bert_score" target="_blank" rel="noopener noreferrer">https://github.com/Tiiiger/bert_score<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><h2 id="introduction" tabindex="-1"><a class="header-anchor" href="#introduction" aria-hidden="true">#</a> Introduction</h2><p>In the ever-evolving realm of machine learning, particularly within Natural Language Processing (NLP) and Large Language Models (LLMs), the demand for robust evaluation metrics has reached a critical turning point. Assessing the accuracy of machine translation (MT) poses a big challenge, given the intricate nature of algorithmically determining semantic equivalence between sentences. While human judgment remains a cornerstone for MT evaluation metrics, the prevalent approach of gauging similarity by examining word order and usage lacks a nuanced understanding of underlying meanings. Addressing this gap, this article delves into a novel solution – BERTScore.</p><p>Introduced as a neural-network-based sentence representation by Google in October 2018, BERT (Bidirectional Encoder Representations from Transformers) stands as a important force in NLP. Developed on the foundations of the Transformer architecture initially tailored for machine translation, BERT undergoes training to predict masked-out words and evaluate sentence coherence. This unique training methodology yields informative sentence representations, propelling BERT to be the leader in various NLP tasks, including sentiment analysis, paraphrase detection, question-answering, and syntactic analysis.</p><p>As part of the ongoing research in evaluation metrics, BERTScore emerges as a unique method. Leveraging contextual embeddings from the BERT model, BERTScore looks beyond word count to understand the meaning of words in a sentence. Instead of solely looking for word similarity, it assesses how effectively sentences convey identical ideas, thus offering a more nuanced understanding of semantic equivalence. This article elucidates the existing limitations of current metrics and explores how BERTScore surpasses them, explaining a new technique in the assessment of sentence similarity and machine-generated text quality.</p><h2 id="issues-with-current-metrics" tabindex="-1"><a class="header-anchor" href="#issues-with-current-metrics" aria-hidden="true">#</a> Issues with current metrics</h2><p>Lexical overlap metrics, such as BLEU (Bilingual Evaluation Understudy), have been longstanding tools for evaluating the quality of machine-generated text. However, they come with inherent limitations that become particularly evident in scenarios where the goal is to measure the semantic similarity between sentences rather than mere lexical similarity.</p><p>Semantic Gap in Lexical Overlap Metrics: The figure clearly illustrates a limitation of metrics like BLEU—they struggle to capture the nuanced semantics of sentences. This is because BLEU primarily relies on the matching of n-grams (contiguous sequences of words), without considering the contextual meaning or the order in which words appear. As a result, sentences that convey the same meaning but differ in word choice or structure may receive low scores, leading to an inaccurate representation of their similarity.</p><p>BERTScore&#39;s Semantic Understanding: BERTScore, on the other hand, addresses this limitation by leveraging the power of pre-trained BERT models. BERT&#39;s bidirectional contextual embeddings allow it to grasp the nuanced semantics of language, considering not only the presence of words but also their contextual relationships. This enables BERTScore to provide high scores for sentences that convey the same meaning, even if they exhibit lexical variations.</p><p>Word Order and Semantic Nuances: Another drawback of lexical overlap metrics, especially when evaluating on uni-grams, is their inability to account for variations in word order. Sentences with the same words but different structures may have distinct meanings, yet traditional metrics might overlook these differences. BERTScore, by considering the entire sentence and its contextual embeddings, naturally accommodates variations in word order, providing a more comprehensive evaluation of semantic similarity.</p><p>Capturing Paraphrasing and Synonyms: Lexical overlap metrics often struggle with paraphrased or synonymous expressions, as they might not share exact n-grams. In contrast, BERTScore excels in recognizing paraphrased or synonymous sentences, as it focuses on the underlying semantic content rather than rigid word matching. This makes BERTScore particularly valuable in applications where variations in expression are common.</p><p>Advancements in Natural Language Understanding: The shift from traditional lexical metrics to embeddings-based metrics like BERTScore reflects the broader trend in NLP toward models that prioritize natural language understanding. As language models evolve to capture semantic nuances, metrics that align with this understanding become increasingly essential for accurate model evaluation.</p><p>In conclusion, while lexical overlap metrics have their place in evaluating certain aspects of generated text, they fall short when it comes to capturing the rich semantic content and contextual nuances of language. BERTScore, with its ability to generate embeddings that encapsulate the semantics of sentences, provides a more nuanced and accurate measure of text similarity, making it a valuable addition to the toolkit for evaluating the performance of NLP models.</p><h2 id="how-bertscore-works" tabindex="-1"><a class="header-anchor" href="#how-bertscore-works" aria-hidden="true">#</a> How BERTScore works</h2><p>BERTScore uses contextual embeddings from models like BERT to represent the tokens. The advantage of using contextual embeddings is that the same work can have different vector representations depending on the context or the surrounding words. Given a candidate sentence (generated text) and a reference sentence embeddings, BERTScore computes matching using cosine similarity, optionally weighted with inverse document frequency scores. Assume the tokenized reference sentence is represented as x=⟨x1,...,xk⟩ and tokenized candidate sentence is represented as x^=⟨x1^,...,xl^⟩. Token Representation Tokenization involves breaking sown the input sentence into a series of words, where new words are broken down to familiar words that have been observed by the model before. Given the source and target sentence, the tokenizer from BERT is used to tokenize the sentences, after which the embedding model is used to generate a sequence of vectors. As a result, the tokenized reference sentence x = hx1, . . . , xki, is mapped to the generated vectors hx1, . . . , xki. and the tokenized candidate xˆ = hxˆ1, . . . , xˆmi is mapped to the generated vectors hˆx1, . . . , ˆxli. Similarity measure Since the words are now reduced to vectors, we can make use of linear algebra to perform calculations and derive a soft measure of similarity instead of an exact match. To compute this, the cosine similarity of each candidate and reference token is calculated. This is done with the following formula: [formula] BERTScore The similarity measures are used to calculate the Precision and Recall. Recall is calculated using similarity between each token in x to a token in x^. [formula].Precision is calculated using similarity between each token in x^ to a token in x. [formula]. These two measures are combined to calculate precision. Importance weighting To account for the importance of rare words in sentence similarity, the authors experiment with incorporating inverse document frequency (idf) scores derived from the test corpus. Baseline rescaling To scale BERTScore values in the range of 0 and 1, an empirical lower bound based on the Common Crawl monolingual datasets is used and the score values are averaged as below [formula]</p><h2 id="experiments" tabindex="-1"><a class="header-anchor" href="#experiments" aria-hidden="true">#</a> Experiments</h2><p>We evaluate twelve pre-trained contextual embedding models, encompassing variants of BERT, RoBERTa, XLNet, and XLM. The selected models include RoBERTa large for English tasks, BERT Chinese for Chinese tasks, and cased multilingual BERT for other languages. To identify the optimal layer for each model, we utilize the WMT16 dataset for validation.</p><p>For machine translation evaluation, we employ the WMT18 metric dataset, assessing 149 translation systems across 14 language pairs. We use absolute Pearson correlation and Kendall rank correlation for metric quality assessment. Hybrid system experiments involve randomly selecting one candidate sentence for each reference from available systems. Model selection experiments involve ranking 100 randomly selected hybrid systems 100,000 times and reporting the percentage of metric rankings agreeing with human rankings</p><h2 id="results" tabindex="-1"><a class="header-anchor" href="#results" aria-hidden="true">#</a> Results</h2><p>In our machine translation evaluation, we concentrated on system-level correlation, hybrid systems, and model selection, revealing the consistent superiority of BERTSCORE. BERTSCORE consistently outperformed other metrics, including the competitive RUSE, especially in to-English results. Notably, RUSE&#39;s dependence on specific human judgment data limited its application in certain experiments.</p><p>The segment-level analysis emphasized BERTSCORE&#39;s significant advantage over traditional metrics like BLEU. BERTSCORE&#39;s marked improvement over BLEU makes it particularly effective for scrutinizing specific examples, where traditional metrics may fall short. BERTSCORE even surpassed RUSE in segment-level performance.</p><p>While idf weighting showed occasional benefits, its impact varied across scenarios. Determining the advantageous use of idf weighting remains an area for future research, contingent on text domain and available test data. For the rest of our experiments, we proceeded without idf weighting.</p><p>Regarding precision (PBERT), recall (RBERT), and F1 (FBERT), we found that F1 consistently performed well across diverse settings, making it our recommended metric. Our study provides a comprehensive view of results, including experiments with idf weighting, various contextual embedding models, and model selection.</p><table><thead><tr><th>Metric</th><th>en↔cs</th><th>en↔de</th><th>en↔et</th><th>en↔fi</th><th>en↔ru</th><th>en↔tr</th><th>en↔zh</th></tr></thead><tbody><tr><td>BLEU</td><td>.970/.995</td><td>.971/.981</td><td>.986/.975</td><td>.973/.962</td><td>.979/.983</td><td>.657/.826</td><td>.978/.947</td></tr><tr><td>ITER</td><td>.975/.915</td><td>.990/.984</td><td>.975/.981</td><td>.996/.973</td><td>.937/.975</td><td>.861/.865</td><td>.980/–</td></tr><tr><td>RUSE</td><td>.981/–</td><td>.997/–</td><td>.990/–</td><td>.991/–</td><td>.988/–</td><td>.853/–</td><td>.981/–</td></tr><tr><td>YiSi-1</td><td>.950/.987</td><td>.992/.985</td><td>.979/.979</td><td>.973/.940</td><td>.991/.992</td><td>.958/.976</td><td>.951/.963</td></tr><tr><td>PBERT</td><td>.980/.994</td><td>.998/.988</td><td>.990/.981</td><td>.995/.957</td><td>.982/.990</td><td>.791/.935</td><td>.981/.954</td></tr><tr><td>RBERT</td><td>.998/.997</td><td>.997/.990</td><td>.986/.980</td><td>.997/.980</td><td>.995/.989</td><td>.054/.879</td><td>.990/.976</td></tr><tr><td>FBERT</td><td>.990/.997</td><td>.999/.989</td><td>.990/.982</td><td>.998/.972</td><td>.990/.990</td><td>.499/.908</td><td>.988/.967</td></tr><tr><td>FBERT (idf)</td><td>.985/.995</td><td>.999/.990</td><td>.992/.981</td><td>.992/.972</td><td>.991/.991</td><td>.826/.941</td><td>.989/.973</td></tr></tbody></table><p>Table 1: Absolute Pearson correlations with system-level human judgments on WMT18. For each language pair, the left number is the to-English correlation, and the right is the from-English.</p><table><thead><tr><th>Metric</th><th>en↔cs</th><th>en↔de</th><th>en↔et</th><th>en↔fi</th><th>en↔ru</th><th>en↔tr</th><th>en↔zh</th></tr></thead><tbody><tr><td>BLEU</td><td>.233/.389</td><td>.415/.620</td><td>.285/.414</td><td>.154/.355</td><td>.228/.330</td><td>.145/.261</td><td>.178/.311</td></tr><tr><td>ITER</td><td>.198/.333</td><td>.396/.610</td><td>.235/.392</td><td>.128/.311</td><td>.139/.291</td><td>-.029/.236</td><td>.144/–</td></tr><tr><td>RUSE</td><td>.347/–</td><td>.498/–</td><td>.368/–</td><td>.273/–</td><td>.311/–</td><td>.259/–</td><td>.218/–</td></tr><tr><td>YiSi-1</td><td>.319/.496</td><td>.488/.691</td><td>.351/.546</td><td>.231/.504</td><td>.300/.407</td><td>.234/.418</td><td>.211/.323</td></tr><tr><td>PBERT</td><td>.387/.541</td><td>.541/.715</td><td>.389/.549</td><td>.283/.486</td><td>.345/.414</td><td>.280/.328</td><td>.248/.337</td></tr><tr><td>RBERT</td><td>.388/.570</td><td>.546/.728</td><td>.391/.594</td><td>.304/.565</td><td>.343/.420</td><td>.290/.411</td><td>.255/.367</td></tr><tr><td>FBERT</td><td>.404/.562</td><td>.550/.728</td><td>.397/.586</td><td>.296/.546</td><td>.353/.423</td><td>.292/.399</td><td>.264/.364</td></tr><tr><td>FBERT (idf)</td><td>.408/.553</td><td>.550/.721</td><td>.395/585</td><td>.293/.537</td><td>.346/.425</td><td>.296/.406</td><td>.260/.366</td></tr></tbody></table><p>Table 2: Kendall correlations with segment-level human judgments on WMT18. For each language pair, the left number is the to-English correlation, and the right is the from-English.</p><p>In our experiments with the WMT dataset and BERTScore evaluation metric, we observed the following results.</p><table><thead><tr><th>Metric</th><th>cs-en</th><th>de-en</th><th>et-en</th><th>fi-en</th><th>ru-en</th><th>tr-en</th><th>zh-en</th><th>avg</th></tr></thead><tbody><tr><td>PBERT</td><td>0.386692759295499</td><td>0.5414273046227397</td><td>0.3891856631582659</td><td>0.2833588957055215</td><td>0.34505959246443674</td><td>0.2802346041055718</td><td>0.2483136972749348</td><td>0.3534675023752814</td></tr><tr><td>RBERT</td><td>0.387866927592955</td><td>0.5460024932207529</td><td>0.39140706263993935</td><td>0.3040644171779141</td><td>0.34256055363321797</td><td>0.2898533724340176</td><td>0.2548490571694097</td><td>0.3595148405526009</td></tr><tr><td>FBERT</td><td>0.4035225048923679</td><td>0.5496780660832016</td><td>0.3971897533541369</td><td>0.2962678936605317</td><td>0.3533256439830834</td><td>0.29196480938416425</td><td>0.2635428845519681</td><td>0.36507022227277913</td></tr></tbody></table><h2 id="references" tabindex="-1"><a class="header-anchor" href="#references" aria-hidden="true">#</a> References</h2></div><!----><footer class="page-meta"><div class="meta-item edit-link"><a href="https://github.com/aninditr/blog/edit/main/BERTScore/README.md" rel="noopener noreferrer" target="_blank" aria-label="Edit this page" class="nav-link label"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewbox="0 0 1024 1024" fill="currentColor" aria-label="edit icon"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->Edit this page<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!----></a></div><div class="meta-item update-time"><span class="label">Last update: </span><span class="info">11/19/2023, 11:23:02 PM</span></div><div class="meta-item contributors"><span class="label">Contributors: </span><!--[--><!--[--><span class="contributor" title="email: aninditr@andrew.cmu.edu">aninditr</span>,<!--]--><!--[--><span class="contributor" title="email: srik8552@gmail.com">Srikumar Subramanian</span><!--]--><!--]--></div></footer><!----><div class="giscus-wrapper input-top" style="display:block;"><div style="text-align:center">Loading...</div></div><!----><!--]--></main><!--]--><footer class="footer-wrapper"><div class="footer"></div><div class="copyright">Copyright © 2023 Aninditha Ramesh, Srikumar Subramanian</div></footer><!--]--></div><!--]--><!----><!--]--></div>
    <script type="module" src="/blog/assets/app.a2f2e5e3.js" defer></script>
  </body>
</html>
